import os
import re
from typing import Dict, Any

# í…ìŠ¤íŠ¸ í¬ë§·í„° import ì¶”ê°€
from utils.text_formatter import format_manual_response

class AnswerGenerator:
    def __init__(self):
        self.openai_available = bool(os.getenv("OPENAI_API_KEY"))

    async def generate_answer(self, question: str, section_data: Dict[str, Any]) -> str:
        """ì„¹ì…˜ ë°ì´í„°ë¡œ ê°„ê²°í•˜ê³  ì •ì œëœ ë‹µë³€ ìƒì„±"""

        self._print_debug_info(question, section_data)

        if self.openai_available:
            raw_answer = await self._generate_openai_answer(question, section_data)
        else:
            raw_answer = self._generate_smart_summary_answer(question, section_data)

        # í¬ë§·íŒ… ì ìš©
        formatted_answer = format_manual_response(
            raw_answer,
            section_data.get("title", ""),
            section_data.get("page_range")
        )

        return formatted_answer

    def _print_debug_info(self, question: str, section_data: Dict[str, Any]):
        """ë””ë²„ê¹… ì •ë³´ ì¶œë ¥"""
        content_preview = section_data['content'][:200]
        full_content_length = len(section_data['content'])

        print(f"ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘ - ì„¹ì…˜: {section_data['title']}")
        print(f"   ì „ì²´ ë‚´ìš© ê¸¸ì´: {full_content_length}ì")
        print(f"   ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content_preview}...")

    async def _generate_openai_answer(self, question: str, section_data: Dict[str, Any]) -> str:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ë‹¨ê³„ë³„ êµ¬ì¡°í™”ëœ ë‹µë³€ ìƒì„±"""

        # ë‚´ìš© ì „ì²˜ë¦¬ - ì¤‘ë³µ ì œê±°
        cleaned_content = self._clean_content(section_data['content'])
        
        # ì§ˆë¬¸ ì˜ë„ íŒŒì•…
        question_intent = self._analyze_question_intent(question)

        prompt = f"""
ì‚¬ìš©ìê°€ "{question}"ì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤.

ì§ˆë¬¸ ì˜ë„: {question_intent}

ë‹¤ìŒ ë§¤ë‰´ì–¼ ë‚´ìš©ì—ì„œ ë‹¨ê³„ë³„ ì ˆì°¨ë¥¼ ì°¾ì•„ êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

{cleaned_content[:1000]}

ë‹µë³€ ê·œì¹™:
1. ì‹¤ì œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ë‹¨ê³„ë“¤ì„ ë²ˆí˜¸ìˆœìœ¼ë¡œ ë‚˜ì—´
2. ê° ë‹¨ê³„ëŠ” êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ
3. 3-6ë‹¨ê³„ ì •ë„ë¡œ êµ¬ì„±
4. ì¤‘ìš”í•œ ì£¼ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ë³„ë„ë¡œ ì–¸ê¸‰
5. ì¤‘ë³µ í‘œí˜„ ì ˆëŒ€ ê¸ˆì§€

ë‹µë³€ í˜•ì‹:
1. ì²« ë²ˆì§¸ ë‹¨ê³„
2. ë‘ ë²ˆì§¸ ë‹¨ê³„
3. ì„¸ ë²ˆì§¸ ë‹¨ê³„
...

ë‹µë³€:
"""

        try:
            import openai
            client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.1
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            print(f"OpenAI ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_smart_summary_answer(question, section_data)

    def _generate_smart_summary_answer(self, question: str, section_data: Dict[str, Any]) -> str:
        """ì§ˆë¬¸ ë§ì¶¤í˜• ìŠ¤ë§ˆíŠ¸ ìš”ì•½ (ëª¨ë“  ì£¼ì œ ëŒ€ì‘)"""
        
        content = self._clean_content(section_data['content'])
        question_intent = self._analyze_question_intent(question)
        
        # ì§ˆë¬¸ ì˜ë„ì— ë”°ë¥¸ í‚¤ì›Œë“œ í•„í„°ë§ (í™•ì¥)
        keyword_map = {
            "ì ê²€ ë°©ë²•": ["ì ê²€", "í™•ì¸", "ì²´í¬", "ì‚´í´", "ê²€ì‚¬", "ì¸¡ì •"],
            "êµì²´ ë°©ë²•": ["êµì²´", "êµí™˜", "ê°ˆê¸°", "ë°”ê¾¸ê¸°", "ì„¤ì¹˜", "ì¥ì°©"],
            "ê´€ë¦¬ ë°©ë²•": ["ê´€ë¦¬", "ìœ ì§€", "ë³´ê´€", "ì²­ì†Œ", "ì •ë¹„", "ì†ì§ˆ"],
            "ë¬¸ì œ í•´ê²°": ["ê³ ì¥", "ë¬¸ì œ", "ì´ìƒ", "ì˜¤ë¥˜", "í•´ê²°", "ìˆ˜ë¦¬"],
            "ì‹¤í–‰ ë°©ë²•": ["ë°©ë²•", "ì ˆì°¨", "ë‹¨ê³„", "ê³¼ì •", "ìˆœì„œ"],
            "ì¼ë°˜ ì •ë³´": ["í•˜ì‹­ì‹œì˜¤", "í•˜ì„¸ìš”", "ì£¼ì˜", "ê²½ê³ ", "ê¶Œì¥"]
        }
        
        target_keywords = keyword_map.get(question_intent, keyword_map["ì¼ë°˜ ì •ë³´"])
        
        # ê´€ë ¨ ë¬¸ì¥ë§Œ ì¶”ì¶œ
        sentences = content.split('.')
        relevant_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if (len(sentence) > 8 and 
                any(keyword in sentence for keyword in target_keywords) and
                not any(avoid in sentence for avoid in ['WL_', 'ì •ê¸° ì ê²€', '666', '667', '668', '669', '670', '671'])):
                relevant_sentences.append(sentence)
            
            if len(relevant_sentences) >= 5:  # ìµœëŒ€ 5ë¬¸ì¥
                break
        
        # í´ë°±: ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ë“¤
        if not relevant_sentences:
            for sentence in sentences[:8]:
                sentence = sentence.strip()
                if len(sentence) > 15 and 'í•˜ì‹­ì‹œì˜¤' in sentence:
                    relevant_sentences.append(sentence)
                if len(relevant_sentences) >= 4:
                    break
        
        return '. '.join(relevant_sentences[:4]) + '.' if relevant_sentences else content[:200]

    def _analyze_question_intent(self, question: str) -> str:
        """ì§ˆë¬¸ ì˜ë„ ë¶„ì„"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['ì ê²€', 'í™•ì¸', 'ì²´í¬']):
            return "ì ê²€ ë°©ë²•"
        elif any(word in question_lower for word in ['êµì²´', 'êµí™˜', 'ê°ˆê¸°']):
            return "êµì²´ ë°©ë²•"
        elif any(word in question_lower for word in ['ê´€ë¦¬', 'ìœ ì§€', 'ë³´ê´€']):
            return "ê´€ë¦¬ ë°©ë²•"
        elif any(word in question_lower for word in ['ë¬¸ì œ', 'ê³ ì¥', 'ì´ìƒ']):
            return "ë¬¸ì œ í•´ê²°"
        elif any(word in question_lower for word in ['ë°©ë²•', 'ì–´ë–»ê²Œ', 'ì ˆì°¨']):
            return "ì‹¤í–‰ ë°©ë²•"
        else:
            return "ì¼ë°˜ ì •ë³´"

    def _clean_content(self, content: str) -> str:
        """ë‚´ìš© ì •ë¦¬ - ê°•ë ¥í•œ ì¤‘ë³µ ì œê±°"""
        
        # 1. **ë‹¨ì–´** **ë‹¨ì–´** íŒ¨í„´ ì œê±°
        content = re.sub(r'\*\*([^*]+)\*\*\s*\*\*\1\*\*', r'**\1**', content)
        
        # 2. ì—°ì†ëœ ê°™ì€ ë‹¨ì–´ ì œê±° (ë°°í„°ë¦¬ ë°°í„°ë¦¬ -> ë°°í„°ë¦¬)
        content = re.sub(r'(\b[ê°€-í£]+)\s+\1', r'\1', content)
        
        # 3. ì˜ë¯¸ì—†ëŠ” ì½”ë“œ ì œê±°
        content = re.sub(r'(WL_\w+)', '', content)
        content = re.sub(r'(ì •ê¸° ì ê²€\s*\d+)', '', content)
        content = re.sub(r'(2C_\w+)', '', content)
        
        # 4. ì¤‘ë³µ ë¬¸ì¥ ì œê±°
        sentences = content.split('.')
        seen = set()
        unique_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            normalized = re.sub(r'\s+', ' ', sentence.lower())
            
            if normalized and len(normalized) > 10 and normalized not in seen:
                seen.add(normalized)
                unique_sentences.append(sentence)
        
        # 5. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        cleaned = '. '.join(unique_sentences)
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        return cleaned.strip()

    def _extract_question_keywords(self, question: str) -> list:
        """ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        keyword_mapping = {
            "ì ê²€": ["ì ê²€", "í™•ì¸", "ì²´í¬", "ê´€ë¦¬"],
            "êµì²´": ["êµì²´", "êµí™˜", "ê°ˆê¸°", "ë°”ê¾¸ê¸°"],
            "ë°©ë²•": ["ë°©ë²•", "ì ˆì°¨", "ê³¼ì •", "ì–´ë–»ê²Œ"],
            "ì£¼ì˜": ["ì£¼ì˜", "ê²½ê³ ", "ì•ˆì „", "ìœ„í—˜"],
            "ê´€ë¦¬": ["ê´€ë¦¬", "ìœ ì§€", "ë³´ê´€", "ì •ë¹„"]
        }
        
        keywords = []
        question_lower = question.lower()
        
        for key, synonyms in keyword_mapping.items():
            if any(syn in question_lower for syn in synonyms):
                keywords.extend(synonyms)
        
        # ì§ˆë¬¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ
        words = re.findall(r'[ê°€-í£]{2,}', question)
        keywords.extend(words)
        
        return list(set(keywords))

    def _extract_relevant_sentences(self, content: str, keywords: list) -> list:
        """í‚¤ì›Œë“œì™€ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì¥ë“¤ ì¶”ì¶œ"""
        
        sentences = [s.strip() for s in content.split('.') if s.strip()]
        relevant = []
        
        for sentence in sentences:
            score = 0
            sentence_lower = sentence.lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            for keyword in keywords:
                if keyword in sentence_lower:
                    score += 2
            
            # ì‹¤ìš©ì  í‘œí˜„ ë³´ë„ˆìŠ¤
            practical_words = ["í•˜ì‹­ì‹œì˜¤", "í•˜ì„¸ìš”", "ë°©ë²•", "ì ˆì°¨", "ì£¼ì˜", "ê²½ê³ ", "í™•ì¸"]
            for word in practical_words:
                if word in sentence:
                    score += 1
            
            # ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì§§ì€ ë¬¸ì¥ ì œì™¸)
            if 10 <= len(sentence) <= 100 and score > 0:
                relevant.append((sentence, score))
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        relevant.sort(key=lambda x: x[1], reverse=True)
        return [sent for sent, score in relevant[:10]]

    def _extract_key_points(self, sentences: list, keywords: list) -> list:
        """í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ ë° ì •ì œ"""
        
        key_points = []
        seen_content = set()
        
        for sentence in sentences:
            # ì¤‘ë³µ ì œê±°
            normalized = re.sub(r'\s+', ' ', sentence.lower())
            if normalized in seen_content:
                continue
            seen_content.add(normalized)
            
            # ë¬¸ì¥ ì •ì œ
            clean_sentence = self._clean_sentence(sentence)
            
            if clean_sentence and len(clean_sentence) > 5:
                key_points.append(clean_sentence)
            
            if len(key_points) >= 5:  # ìµœëŒ€ 5ê°œ
                break
        
        return key_points

    def _clean_sentence(self, sentence: str) -> str:
        """ê°œë³„ ë¬¸ì¥ ì •ì œ"""
        
        # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
        sentence = re.sub(r'[^\w\sê°€-í£.,()/-]', '', sentence)
        
        # ì—°ì† ê³µë°± ì œê±°
        sentence = re.sub(r'\s+', ' ', sentence)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        sentence = sentence.strip()
        
        # ë¬¸ì¥ ë ì •ë¦¬
        if sentence and not sentence.endswith(('.', 'ìš”', 'ë‹¤', 'ì˜¤')):
            sentence += '.'
        
        return sentence