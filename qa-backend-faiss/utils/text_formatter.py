import re

def format_response(raw_text: str) -> str:
    """ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê°€ë…ì„± ìˆê²Œ í¬ë§·íŒ… - ë§¤ë‰´ì–¼ ë‚´ìš© ì™„ì „ ë³´ì¡´"""
    
    # 0. ì¤‘ë³µ ë‹¨ì–´ ì •ë¦¬ (ì˜ˆ: **ì—”ì§„** **ì˜¤ì¼** -> **ì—”ì§„ ì˜¤ì¼**)
    formatted = re.sub(r'\*\*([^*]+)\*\*\s*\*\*([^*]+)\*\*', r'**\1 \2**', raw_text)
    formatted = re.sub(r'\*\*([^*]+)\*\*\s*\*\*\1\*\*', r'**\1**', formatted)
    
    # 1. ë‹¨ê³„ë³„ ë²ˆí˜¸ ì¶”ì¶œ ë° êµ¬ì¡°í™” (ì™„ì „ ë³´ì¡´ ë°©ì‹)
    formatted = extract_and_format_steps_complete(formatted)
    
    # 2. í˜ì´ì§€ ì°¸ì¡° ì œê±° (í•˜ë‹¨ì— í†µí•© í‘œì‹œ)
    formatted = re.sub(r'\(í˜ì´ì§€:\s*\d+\)', '', formatted)
    
    # 3. ì¤‘ìš” ì •ë³´ ê°•ì¡° (ì£¼ì˜ì‚¬í•­ í…ìŠ¤íŠ¸ ì •ë¦¬ ì¶”ê°€)
    formatted = re.sub(r'(F-Lì„ |ì•½ 15ë¶„|ì •ìƒ ì˜¨ë„|ëƒ‰ê°ìˆ˜ ì˜¨ë„|ê·œì •ëŸ‰|ë ˆë²¨ ê²Œì´ì§€)', r'**\1**', formatted)
    
    # ì£¼ì˜ì‚¬í•­ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬
    formatted = re.sub(r'\*\*ì£¼ì˜ì‚¬í•­:\*\*\s*', '', formatted)
    
    # 4. ì˜¨ë„/ì‹œê°„ ê´€ë ¨ ê°•ì¡°
    formatted = re.sub(r'(ì•½ \d+ë¶„|ì •ìƒ ì˜¨ë„|ì¼ì •í•œ ì •ìƒ ì˜¨ë„)', r'**\1**', formatted)
    
    # 5. ì£¼ì œë³„ ì œëª© ìë™ ìƒì„±
    formatted = add_topic_title(formatted)
    
    # 6. ì¤‘ìš” ì•ˆë‚´ì‚¬í•­ í•˜ì´ë¼ì´íŠ¸
    if 'ì§ì˜ í•˜ì´í…Œí¬ì„¼í„°' in formatted or 'ë¸”ë£¨í•¸ì¦ˆ' in formatted:
        formatted = re.sub(
            r'(.*ì§ì˜ í•˜ì´í…Œí¬ì„¼í„°.*ë¸”ë£¨í•¸ì¦ˆ.*)',
            r'\n\n## âš ï¸ ì¤‘ìš” ì•ˆë‚´ì‚¬í•­\n**\1**',
            formatted
        )
    
    # 7. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    formatted = re.sub(r'\n\s*\n\s*\n', '\n\n', formatted)
    
    # 8. ì¤‘ë³µ ë¬¸ì¥ ì œê±° (ì™„í™”ëœ ë²„ì „)
    formatted = remove_duplicate_sentences_gentle(formatted)
    
    return formatted.strip()


def extract_and_format_steps_complete(text: str) -> str:
    """ë‹¨ê³„ë³„ ì ˆì°¨ ì¶”ì¶œ ë° í¬ë§·íŒ… - ëª¨ë“  ë‚´ìš© ë³´ì¡´"""
    
    # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë” ì •í™•í•˜ê²Œ ë¶„ë¦¬
    sentences = re.split(r'\.(?=\s+[A-Zê°€-í£]|\s*$)', text)
    sentences = [s.strip() + ('.' if not s.strip().endswith('.') and s.strip() else '') for s in sentences if s.strip()]
    
    # ì‹¤ì œ ì ˆì°¨ì  ë¬¸ì¥ë§Œ ì„ ë³„ (ë” ì—„ê²©í•œ ê¸°ì¤€)
    procedure_patterns = [
        r'.*(?:ì£¼ì°¨í•˜ê³ |ì˜ˆì—´í•˜ì—¬|ë„ê³ |ë½‘ì•„|ê¸°ë‹¤ë¦¬|ë‹¦ìœ¼|ê½‚ì€|í™•ì¸í•˜ì‹­ì‹œì˜¤|ë³´ì¶©í•˜ì‹­ì‹œì˜¤|ë‹«ê³ )',
        r'^\d+\.\s*.*(?:í•˜ì‹­ì‹œì˜¤|í•˜ì„¸ìš”)$',
        r'.*(?:ë¨¼ì €|ë‹¤ìŒì—|ê·¸ í›„|ë§ˆì§€ë§‰ìœ¼ë¡œ).*(?:í•˜ì‹­ì‹œì˜¤|í•˜ì„¸ìš”)'
    ]
    
    steps = []
    other_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) < 5:
            continue
            
        # ì ˆì°¨ì  ë¬¸ì¥ì¸ì§€ í™•ì¸
        is_procedure = any(re.match(pattern, sentence, re.IGNORECASE) for pattern in procedure_patterns)
        
        if is_procedure:
            # ë¬¸ì¥ ëì˜ ë‹¨ë… ìˆ«ì ì œê±°
            cleaned_sentence = re.sub(r'\.\s*\d+\.\s*$', '.', sentence)
            steps.append(cleaned_sentence)
        else:
            other_sentences.append(sentence)
    
    # ë‹¨ê³„ë³„ í˜•ì‹ ì ìš© (ì‹¤ì œ ì ˆì°¨ê°€ 3ê°œ ì´ìƒì¼ ë•Œë§Œ)
    if len(steps) >= 3:
        formatted_steps = []
        for i, step in enumerate(steps, 1):
            # ê¸°ì¡´ ë²ˆí˜¸ ì œê±°
            step = re.sub(r'^\d+\.\s*', '', step)
            step = re.sub(r'\s*\d+\.\s*$', '', step)
            step = step.strip()
            if not step.endswith('.'):
                step += '.'
            formatted_steps.append(f"**{i}.** {step}")
        
        result = '\n\n'.join(formatted_steps)
        
        # ì£¼ì˜ì‚¬í•­ê³¼ ì¶”ê°€ ì •ë³´ë¥¼ í•˜ë‚˜ë¡œ í†µí•©
        all_additional_info = []
        seen_info = set()
        
        for sentence in other_sentences:
            # ë¬¸ì¥ ë ë²ˆí˜¸ ì œê±°
            cleaned = re.sub(r'\.\s*\d+\.\s*$', '.', sentence)
            
            # ì¤‘ë³µ ì²´í¬
            normalized = re.sub(r'\*\*.*?\*\*', '', cleaned).strip().lower()
            normalized = re.sub(r'ì£¼ì˜ì‚¬í•­:\s*', '', normalized)
            
            if normalized not in seen_info and len(cleaned) > 10:
                seen_info.add(normalized)
                all_additional_info.append(cleaned)
        
        # ì£¼ì˜ì‚¬í•­ê³¼ ì¼ë°˜ ì •ë³´ ë¶„ë¦¬
        important_info = []
        remaining_info = []
        
        for info in all_additional_info:
            if any(keyword in info for keyword in ['ì£¼ì˜', 'ê²½ê³ ', 'ì¤‘ìš”', 'ê¶Œì¥', 'ì¶”ì²œ', 'ì°¸ê³ ', 'ì•Œì•„ë‘ê¸°', 'ì•ˆì „', 'ì£¼ì˜ì‚¬í•­', 'ê²½ê³ ì‚¬í•­']):
                important_info.append(info)
            else:
                remaining_info.append(info)
        
        if important_info:
            result += '\n\n## âš ï¸ ì£¼ì˜ì‚¬í•­\n' + '\n'.join([f"â€¢ **{info}**" for info in important_info])
        
        if remaining_info:
            result += '\n\n## ğŸ“‹ ì¶”ê°€ ì •ë³´\n' + '\n'.join([f"â€¢ {info}" for info in remaining_info])
        
        return result
    else:
        # ì ˆì°¨ê°€ ì ìœ¼ë©´ ê°„ê²°í•˜ê²Œ ì •ë¦¬
        all_sentences = steps + other_sentences
        
        main_info = []
        important_info = []
        seen_info = set()
        
        for sentence in all_sentences:
            # ë¬¸ì¥ ë ë²ˆí˜¸ ì œê±°
            cleaned = re.sub(r'\.\s*\d+\.\s*$', '.', sentence)
            
            # ì¤‘ë³µ ì²´í¬
            normalized = re.sub(r'\*\*.*?\*\*', '', cleaned).strip().lower()
            normalized = re.sub(r'ì£¼ì˜ì‚¬í•­:\s*', '', normalized)
            
            if normalized not in seen_info and len(cleaned) > 10:
                seen_info.add(normalized)
                
                if any(keyword in cleaned for keyword in ['ì£¼ì˜', 'ê²½ê³ ', 'ì¤‘ìš”', 'ê¶Œì¥', 'ì¶”ì²œ', 'ì°¸ê³ ', 'ì•Œì•„ë‘ê¸°', 'ì•ˆì „', 'ì£¼ì˜ì‚¬í•­', 'ê²½ê³ ì‚¬í•­']):
                    important_info.append(cleaned)
                else:
                    main_info.append(cleaned)
        
        result = '\n\n'.join([f"â€¢ {info}" for info in main_info])
        
        if important_info:
            result += '\n\n## âš ï¸ ì£¼ì˜ì‚¬í•­\n' + '\n'.join([f"â€¢ **{info}**" for info in important_info])
                
        return result
    
    # ì ˆì°¨ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return text


def add_topic_title(text: str) -> str:
    """ì£¼ì œì™€ í–‰ë™ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì œëª© ìƒì„±"""
    
    if text.startswith('#'):
        return text
    
    # ì£¼ì œ-í–‰ë™-ì´ëª¨ì§€ ë§¤í•‘
    topics = {
        'ì—”ì§„ ì˜¤ì¼': 'ğŸ”§', 'ì—”ì§„ì˜¤ì¼': 'ğŸ”§', 'ë°°í„°ë¦¬': 'ğŸ”‹', 'íƒ€ì´ì–´': 'ğŸš—',
        'ë¸Œë ˆì´í¬': 'ğŸ›‘', 'í•„í„°': 'ğŸŒ€', 'ëƒ‰ê°ìˆ˜': 'â„ï¸', 'ì—ì–´ì»¨': 'ğŸŒ¬ï¸',
        'íˆí„°': 'ğŸ”¥', 'ì „êµ¬': 'ğŸ’¡', 'í“¨ì¦ˆ': 'âš¡', 'ë²¨íŠ¸': 'ğŸ”—', 'ì™€ì´í¼': 'ğŸŒ§ï¸',
        'ì‹œë™': 'ğŸ”‘', 'ë³€ì†ê¸°': 'âš™ï¸', 'ì¡°í–¥': 'ğŸ¯', 'ì„œìŠ¤íœì…˜': 'ğŸ—ï¸', 'ë°°ê¸°': 'ğŸ’¨'
    }
    
    actions = {
        'ì ê²€ ì£¼ê¸°': 'ì ê²€ ì£¼ê¸°', 'ì •ê¸° ì ê²€': 'ì •ê¸° ì ê²€ ì£¼ê¸°',
        'ì ê²€': 'ì ê²€ ë°©ë²•', 'í™•ì¸': 'í™•ì¸ ë°©ë²•', 'êµì²´': 'êµì²´ ë°©ë²•',
        'êµí™˜': 'êµì²´ ë°©ë²•', 'ê´€ë¦¬': 'ê´€ë¦¬ ë°©ë²•', 'ì •ë¹„': 'ì •ë¹„ ë°©ë²•',
        'ìˆ˜ë¦¬': 'ìˆ˜ë¦¬ ë°©ë²•', 'ì¡°ì •': 'ì¡°ì • ë°©ë²•', 'ì„¤ì •': 'ì„¤ì • ë°©ë²•',
        'ì‚¬ìš©': 'ì‚¬ìš© ë°©ë²•', 'ì‘ë™': 'ì‘ë™ ë°©ë²•', 'ì²­ì†Œ': 'ì²­ì†Œ ë°©ë²•'
    }
    
    # ì£¼ì œì™€ í–‰ë™ ì°¾ê¸°
    found_topic = None
    found_emoji = 'ğŸ“–'
    found_action = 'ì‚¬ìš© ë°©ë²•'
    
    for topic, emoji in topics.items():
        if topic in text:
            found_topic = topic
            found_emoji = emoji
            break
    
    for action, method in actions.items():
        if action in text:
            found_action = method
            break
    
    # ì œëª© ìƒì„±
    if found_topic:
        title = f"# {found_emoji} {found_topic} {found_action}\n\n{text}"
    else:
        if any(word in text for word in ['ì ê²€', 'í™•ì¸']):
            title = f"# ğŸ” ì ê²€ ë°©ë²•\n\n{text}"
        elif any(word in text for word in ['êµì²´', 'êµí™˜']):
            title = f"# ğŸ”§ êµì²´ ë°©ë²•\n\n{text}"
        elif any(word in text for word in ['ê´€ë¦¬', 'ì •ë¹„']):
            title = f"# ğŸ› ï¸ ê´€ë¦¬ ë°©ë²•\n\n{text}"
        else:
            title = f"# ğŸ“– ì‚¬ìš© ë°©ë²•\n\n{text}"
    
    return title


def remove_duplicate_sentences_gentle(text: str) -> str:
    """ì¤‘ë³µ ë¬¸ì¥ ì œê±° - ì™„í™”ëœ ë²„ì „"""
    lines = text.split('\n')
    seen = set()
    result = []
    
    for line in lines:
        if line.startswith('#') or line.startswith('---') or line.startswith('>') or line.startswith('*') or line.startswith('**'):
            result.append(line)
            continue
        
        if not line.strip():
            result.append(line)
            continue
        
        normalized = line.strip()
        if normalized not in seen:
            seen.add(normalized)
            result.append(line)
    
    return '\n'.join(result)


def format_manual_response(raw_text: str, section_title: str = "", page_range: tuple = None) -> str:
    """ë§¤ë‰´ì–¼ ë‹µë³€ ì „ìš© í¬ë§·íŒ… - ëª¨ë“  ë‚´ìš© ë³´ì¡´"""
    
    formatted = format_response(raw_text)
    
    if section_title and not formatted.startswith('#'):
        formatted = f"# ğŸ“– {section_title}\n\n{formatted}"
    
    if page_range:
        formatted += f"\n\n---\n*ì°¸ê³ : ì‚¬ìš©ì ë§¤ë‰´ì–¼ {page_range[0]}-{page_range[1]}í˜ì´ì§€*"
    
    return formatted


def summarize_long_content(text: str) -> str:
    """ê¸´ ë‚´ìš© ìš”ì•½ - ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©"""
    lines = text.split('\n')
    important_lines = []
    
    for line in lines:
        if (line.startswith('#') or 
            line.startswith('**') and '.**' in line or
            'ğŸ’¡' in line or 'âš ï¸' in line or
            any(keyword in line for keyword in ['ì£¼ì˜', 'ê²½ê³ ', 'ì¤‘ìš”', 'ê¶Œì¥', 'ë°©ë²•'])):
            important_lines.append(line)
    
    return '\n'.join(important_lines)